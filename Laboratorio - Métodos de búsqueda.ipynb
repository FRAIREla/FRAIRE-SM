{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28086fca-2cdd-41ac-b7bf-bc1af9f759a2",
   "metadata": {},
   "source": [
    "# Laboratorio: Métodos de búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19abc1-82f0-4f28-9493-468e4227c14f",
   "metadata": {},
   "source": [
    "En las clases anteriores creaste códigos para realizar búsquedas aleatorias (Simulated Annealing) y búsquedas dirigidas (Optimización Bayesiana). Estos métodos de búsqueda se utilizan para facilitar el proceso de optimización de funciones objetivos compleja y costosas de computar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038474ce-6e2f-4d45-895a-bb17f7c8871d",
   "metadata": {},
   "source": [
    "En este laboratorio usaremos el dataset de los diferentes tipos de iris, y sus longitudes y anchos de pétalos y sépalos. Utilizaremos un RandomForest para crear un modelo de clasificación y el métrico F1 para decidir cuál es el mejor modelo de acuerdo a lo que tenemos disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04956ea-14f4-419e-adf8-add3b81da443",
   "metadata": {},
   "source": [
    "1. Carga el dataset de Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad912f2-1359-437e-af68-3c8cca8d1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97ad91-d82b-491c-ac5d-be6f872c5334",
   "metadata": {},
   "source": [
    "2. Importa el archivo `Bosque.py`.\n",
    "\n",
    "Este archivo contiene la función `RegresionBosque`, que recibe:\n",
    "- X: las características independientes\n",
    "- y: la variable de respuesta\n",
    "- árboles: cantidad total de árboles\n",
    "- profundidad de bosque: niveles de profundidad del bosque\n",
    "\n",
    "Su salida es:\n",
    "- modelo: El objeto con el modelo ajustado\n",
    "- f1: El métrico que califica qué tan bueno es el modelo que se ajustó.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f875f1-a72a-4a57-8355-16d6bb9fb33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Bosque\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 10, 3)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac2825-33ac-4919-9ccb-8324701ce99f",
   "metadata": {},
   "source": [
    "### Actividad 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb265f-9ccf-4fb4-b8c0-8fe221ea534c",
   "metadata": {},
   "source": [
    "Inicializa un espacio con 5 muestras en nuestro dominio de variables independientes:\n",
    "- árboles: números enteros entre 5 y 50.\n",
    "- profundidad: números enteros entre 2 y 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7c396-af97-49a6-828e-c5d63c1b6999",
   "metadata": {},
   "source": [
    "Utiliza optimización Bayesiana para encontrar la combinación de árboles y profundidad que **maximice** el métrico F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e563392-4509-4d70-9cb6-adca944d2406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14, 41, 20,  5, 33]), array([3, 7, 2, 7, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "ARB = np.random.randint(5,50,5)\n",
    "PRO = np.random.randint(2,10,5)\n",
    "ARB, PRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de00bcfe-9350-4954-80f6-1ea060276da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9444444444444444,\n",
       " 0.9555555555555556,\n",
       " 0.9333333333333333,\n",
       " 0.9555555555555556,\n",
       " 0.9333333333333333]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POINTS = []\n",
    "for i in range (len(PRO)):\n",
    "    modelo, f1 = Bosque.RegresionBosque(X, y, ARB[i], PRO[i])\n",
    "    POINTS.append(f1)\n",
    "POINTS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce09d31-2b7e-4508-a4e8-c8518cbae843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  3],\n",
       "       [41,  7],\n",
       "       [20,  2],\n",
       "       [ 5,  7],\n",
       "       [33,  3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARB_vect = ARB.reshape([-1,1])\n",
    "PRO_vect = PRO.reshape ([-1,1])\n",
    "HPM = np.hstack((ARB_vect,PRO_vect))\n",
    "HPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467e1c6f-e303-43b4-9d16-91d4f519fc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  3],\n",
       "       [41,  7],\n",
       "       [20,  2],\n",
       "       [ 5,  7],\n",
       "       [33,  3],\n",
       "       [41,  7]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "kernel = 1.0*RBF(length_scale = 1)\n",
    "xA = np.linspace(0,50,5).reshape([-1,1])\n",
    "xP = np.linspace(2,10,5).reshape([-1,1])\n",
    "MAP = np.hstack((xA,xP))\n",
    "gp = GPR(kernel=kernel, n_restarts_optimizer=10).fit(MAP, POINTS)\n",
    "y_pred, y_std = gp.predict(MAP, return_std=True)\n",
    "y_pred_high = y_pred + 1.96*y_std\n",
    "i_next = np.argmax(y_pred_high)\n",
    "new_X= np.vstack((HPM,HPM[i_next]))\n",
    "new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c39de3d3-bad3-42cb-9bbb-8c0647c4d661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41,  7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPM[i_next]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0a7efc5-e2a7-413a-bc66-bae09226b5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo,f1 = Bosque.RegresionBosque(X, y, 41, 7)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe12184-6ca3-4a9b-a5ce-bf3e31a4b9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9444444444444444,\n",
       " 0.9555555555555556,\n",
       " 0.9333333333333333,\n",
       " 0.9555555555555556,\n",
       " 0.9333333333333333,\n",
       " 0.9555555555555556]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POINTS.append(f1)\n",
    "POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c459bb4-9047-4da7-b59c-1568d9eb6703",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.94444444 0.95555556 0.93333333 0.95555556 0.93333333 0.95555556].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m*\u001b[39mRBF(length_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m gp \u001b[38;5;241m=\u001b[39m GPR(kernel\u001b[38;5;241m=\u001b[39mkernel, n_restarts_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(POINTS,new_X)\n\u001b[0;32m      3\u001b[0m y_pred, y_std \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mpredict(POINTS, return_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m y_pred_high \u001b[38;5;241m=\u001b[39m y_pred \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.96\u001b[39m\u001b[38;5;241m*\u001b[39my_std\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    252\u001b[0m     X,\n\u001b[0;32m    253\u001b[0m     y,\n\u001b[0;32m    254\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    255\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    256\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    257\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1264\u001b[0m     X,\n\u001b[0;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1266\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1267\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1268\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1269\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1270\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1271\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1272\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1273\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1274\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1275\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1277\u001b[0m )\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1035\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1029\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1030\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1031\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1032\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1033\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1034\u001b[0m             )\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1041\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.94444444 0.95555556 0.93333333 0.95555556 0.93333333 0.95555556].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "kernel = 1.0*RBF(length_scale = 1)\n",
    "gp = GPR(kernel=kernel, n_restarts_optimizer=10).fit(POINTS,new_X)\n",
    "y_pred, y_std = gp.predict(POINTS, return_std=True)\n",
    "y_pred_high = y_pred + 1.96*y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e083a3c-fa68-4942-b5d3-f1f7130b4fbb",
   "metadata": {},
   "source": [
    "### Actividad 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817a47c-0081-4376-b222-c65735f4ab9d",
   "metadata": {},
   "source": [
    "Inicializa 2 vectores con posibles valores para las variables independientes:\n",
    "- árboles: números enteros entre 5 y 50\n",
    "- profundidad: números enteros entre 2 y 10\n",
    "\n",
    "Utiliza el algoritmo de Simulated Annealing que siga el siguiente orden:\n",
    "- Elige un punto de partida para las variables.\n",
    "- Selecciona al azar una de las dos para modificarlas.\n",
    "- Selecciona un elemento al azar de la lista que contiene los posibles valores de esa variable.\n",
    "- Sigue el algoritmo ($p$ y $q$) para decidir si usas esa combinación nueva o si mantienes la anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c83398-cdb3-4931-beec-066c5c8e9863",
   "metadata": {},
   "source": [
    "ejercico sin utilizar archivo .py\n",
    "razon: falta de conocimiento en el tema \n",
    "        muchos errores \n",
    "        muy tardado\n",
    "        errores de traslado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6286fe8-ec56-4871-9c31-8d4d3ca4c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo entrenado: RandomForestClassifier(max_depth=3, n_estimators=11)\n",
      "Mejor número de árboles: 11\n",
      "Mejor profundidad: 3\n",
      "Mejor F1: 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from math import exp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "def RegresionBosque(X, y, arboles, profundidad):\n",
    "    clf = RandomForestClassifier(n_estimators=arboles, max_depth=profundidad)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    f1 = metrics.f1_score(y_test, pred, average=\"micro\")  \n",
    "    return clf, f1\n",
    "\n",
    "\n",
    "def simulated_annealing(X, y, arboles_range, profundidad_range, T=100, T_min=1, alpha=0.9, max_iter=100):\n",
    "    \n",
    "    current_arboles = random.choice(arboles_range)\n",
    "    current_profundidad = random.choice(profundidad_range)\n",
    "    current_modelo, current_f1 = RegresionBosque(X, y, current_arboles, current_profundidad)\n",
    "\n",
    "    \n",
    "    best_modelo, best_f1 = current_modelo, current_f1\n",
    "    best_arboles, best_profundidad = current_arboles, current_profundidad\n",
    "\n",
    "    while T > T_min:\n",
    "        for _ in range(max_iter):\n",
    "            \n",
    "            variable = random.choice([\"arboles\", \"profundidad\"])\n",
    "            if variable == \"arboles\":\n",
    "                new_arboles = random.choice(arboles_range)\n",
    "                new_profundidad = current_profundidad\n",
    "            else:\n",
    "                new_arboles = current_arboles\n",
    "                new_profundidad = random.choice(profundidad_range)\n",
    "\n",
    "            \n",
    "            new_modelo, new_f1 = RegresionBosque(X, y, new_arboles, new_profundidad)\n",
    "\n",
    "            \n",
    "            delta = new_f1 - current_f1\n",
    "            if delta > 0 or exp(delta / T) > random.random():\n",
    "                \n",
    "                current_arboles, current_profundidad = new_arboles, new_profundidad\n",
    "                current_modelo, current_f1 = new_modelo, new_f1\n",
    "\n",
    "                \n",
    "                if new_f1 > best_f1:\n",
    "                    best_modelo, best_f1 = new_modelo, new_f1\n",
    "                    best_arboles, best_profundidad = new_arboles, new_profundidad\n",
    "\n",
    "        \n",
    "        T *= alpha\n",
    "\n",
    "    \n",
    "    return best_modelo, best_f1, best_arboles, best_profundidad\n",
    "\n",
    "\n",
    "arboles_range = np.arange(5, 51) \n",
    "profundidad_range = np.arange(2, 11) \n",
    "\n",
    "X = np.random.rand(100, 5)  \n",
    "y = np.random.randint(0, 2, 100) \n",
    "\n",
    "best_model, best_f1, best_arboles, best_profundidad = simulated_annealing(X, y, arboles_range, profundidad_range)\n",
    "\n",
    "print(\"Mejor modelo entrenado:\", best_model)\n",
    "print(\"Mejor número de árboles:\", best_arboles)\n",
    "print(\"Mejor profundidad:\", best_profundidad)\n",
    "print(\"Mejor F1:\", best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29af61-6819-45af-a876-baa729486253",
   "metadata": {},
   "source": [
    "Cambio de algoritmo a este de recocido simulado, entra en el campo de la metahuristica y se asimilia en enfriamiento de un metal donde:\n",
    "T: Temperatura inicial.\n",
    "T_min: Temperatura mínima para detener el algoritmo.\n",
    "alpha: Factor de enfriamiento (reduce T en cada iteración).\n",
    "max_iter: Número de iteraciones por nivel de temperatura.\n",
    "Lo utilizamos en este caso por que necesitabamos hacer varias comparaciones para determinar la combinacion que se acercara a nuestras necesidades dadas por el planteamiento del problema, aunque el metrico nos de bajo utilizamos tecnicas nuevas y de mucha utilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "239fa243-bd6d-4ec4-860a-2eae65cea710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo entrenado: RandomForestClassifier(max_depth=10, n_estimators=5)\n",
      "Mejor número de árboles: 5\n",
      "Mejor profundidad: 10\n",
      "Mejor F1: 0.55\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from math import exp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def RegresionBosque(X, y, arboles, profundidad):\n",
    "    clf = RandomForestClassifier(n_estimators=arboles, max_depth=profundidad)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    f1 = metrics.f1_score(y_test, pred, average=\"micro\")  \n",
    "    return clf, f1\n",
    "\n",
    "\n",
    "def simulated_annealing(X, y, arboles_range, profundidad_range, T=10, T_min=1, alpha=0.85, max_iter=50):\n",
    "    \n",
    "    current_arboles = random.choice(arboles_range)\n",
    "    current_profundidad = random.choice(profundidad_range)\n",
    "    current_modelo, current_f1 = RegresionBosque(X, y, current_arboles, current_profundidad)\n",
    "\n",
    "    \n",
    "    best_modelo, best_f1 = current_modelo, current_f1\n",
    "    best_arboles, best_profundidad = current_arboles, current_profundidad\n",
    "\n",
    "   \n",
    "    resultados_cache = {}\n",
    "\n",
    "    while T > T_min:\n",
    "        for _ in range(max_iter):\n",
    "            \n",
    "            variable = random.choice([\"arboles\", \"profundidad\"])\n",
    "            if variable == \"arboles\":\n",
    "                new_arboles = random.choice(arboles_range)\n",
    "                new_profundidad = current_profundidad\n",
    "            else:\n",
    "                new_arboles = current_arboles\n",
    "                new_profundidad = random.choice(profundidad_range)\n",
    "\n",
    "            r\n",
    "            key = (new_arboles, new_profundidad)\n",
    "            if key in resultados_cache:\n",
    "                new_f1 = resultados_cache[key]\n",
    "            else:\n",
    "                new_modelo, new_f1 = RegresionBosque(X, y, new_arboles, new_profundidad)\n",
    "                resultados_cache[key] = new_f1\n",
    "\n",
    "            \n",
    "            delta = new_f1 - current_f1\n",
    "            if delta > 0 or exp(delta / T) > random.random():\n",
    "                \n",
    "                current_arboles, current_profundidad = new_arboles, new_profundidad\n",
    "                current_modelo, current_f1 = new_modelo, new_f1\n",
    "\n",
    "                \n",
    "                if new_f1 > best_f1:\n",
    "                    best_modelo, best_f1 = new_modelo, new_f1\n",
    "                    best_arboles, best_profundidad = new_arboles, new_profundidad\n",
    "\n",
    "        \n",
    "        T *= alpha\n",
    "\n",
    "    \n",
    "    return best_modelo, best_f1, best_arboles, best_profundidad\n",
    "\n",
    "\n",
    "def evaluar_combinacion(X, y, arboles, profundidad):\n",
    "    _, f1 = RegresionBosque(X, y, arboles, profundidad)\n",
    "    return (arboles, profundidad, f1)\n",
    "\n",
    "\n",
    "arboles_range = np.arange(5, 51, 5)  \n",
    "profundidad_range = np.arange(2, 11)  \n",
    "\n",
    "\n",
    "X = np.random.rand(200, 10)  \n",
    "y = np.random.randint(0, 2, 200) \n",
    "\n",
    "\n",
    "best_model, best_f1, best_arboles, best_profundidad = simulated_annealing(X, y, arboles_range, profundidad_range)\n",
    "\n",
    "\n",
    "print(\"Mejor modelo entrenado:\", best_model)\n",
    "print(\"Mejor número de árboles:\", best_arboles)\n",
    "print(\"Mejor profundidad:\", best_profundidad)\n",
    "print(\"Mejor F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e98042-7e13-4c12-8ccf-a20614b9eb5a",
   "metadata": {},
   "source": [
    "En este codigo hay cambios pero no decimos que es mejor que el anterior, de joblib importamos Parallel, delayed para hacer una paralelizacion y evaluar combinanciones mas rapido, este codigo tarda mucho menos en correr que el anterior, implementamos un cache para evitar recomputaciones, implementamos un submuestreo de datos para reducir el tamaño de los conjuntos de entrenamiento y prueba durante las pruebas, reducimos el numero de iteraciones (de 50 a 100), ajustamos a una temperatura incial ( ahora 10 antes 100), solo el 30% de los datos se usa en cada división de train_test_split."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
